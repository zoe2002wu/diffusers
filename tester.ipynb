{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25289c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /n/home00/zoewu/.conda/envs/r-sdxl/bin/python\n",
      "torch: 2.6.0+cu124\n",
      "torch.version.cuda: 12.4\n",
      "torch.backends.cudnn.is_available(): True\n",
      "CUDA visible devices env: None\n",
      "torch.cuda.is_available(): True\n",
      "torch.cuda.device_count(): 1\n",
      "\n",
      "`nvidia-smi` output:\n",
      "Fri Sep 5 20:01:45 2025 +-----------------------------------------------------------------------------------------+ | NVIDIA-SMI 575.57.08 Driver Version: 575.57.08 CUDA Version: 12.9 | |-----------------------------------------+------------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+========================+======================| | 0 NVIDIA A100-SXM4-40GB On | 00000000:31:00.0 Off | 0 | | N/A 25C P0 51W / 400W | 5MiB / 40960MiB | 0% Default | | | | Disabled | +-----------------------------------------+------------------------+----------------------+ ...\n",
      "\n",
      "Host + SLURM:\n",
      "HOSTNAME = holygpu8a19603.rc.fas.harvard.edu\n",
      "SLURM_JOB_ID = 33812505\n",
      "SLURM_JOB_NODELIST = None\n"
     ]
    }
   ],
   "source": [
    "import sys, os, platform, subprocess, textwrap\n",
    "print(\"Python:\", sys.executable)\n",
    "try:\n",
    "    import torch\n",
    "    print(\"torch:\", torch.__version__)\n",
    "    print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "    print(\"torch.backends.cudnn.is_available():\", torch.backends.cudnn.is_available())\n",
    "    print(\"CUDA visible devices env:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "    print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "    print(\"torch.cuda.device_count():\", torch.cuda.device_count())\n",
    "except Exception as e:\n",
    "    print(\"Torch import error:\", e)\n",
    "\n",
    "print(\"\\n`nvidia-smi` output:\")\n",
    "try:\n",
    "    out = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True, timeout=5)\n",
    "    print(textwrap.shorten(out.stdout.strip(), width=800, placeholder=\" ...\"))\n",
    "except Exception as e:\n",
    "    print(\"nvidia-smi error:\", e)\n",
    "\n",
    "print(\"\\nHost + SLURM:\")\n",
    "for k in [\"HOSTNAME\", \"SLURM_JOB_ID\", \"SLURM_JOB_NODELIST\"]:\n",
    "    print(k, \"=\", os.environ.get(k))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r-sdxl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
